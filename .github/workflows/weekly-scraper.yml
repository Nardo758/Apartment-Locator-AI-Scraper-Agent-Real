name: Weekly Scraper Scheduler

on:
  schedule:
    # Run every Sunday at midnight UTC
    - cron: '0 0 * * 0'
  workflow_dispatch:
    inputs:
      region:
        description: 'Target region for scraping'
        required: false
        default: 'all'
        type: choice
        options:
        - all
        - atlanta
        - austin
        - dallas
        - houston
      force_run:
        description: 'Force run even if cost limits exceeded'
        required: false
        default: false
        type: boolean
      dry_run:
        description: 'Perform dry run without actual scraping'
        required: false
        default: false
        type: boolean

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
  SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

jobs:
  pre-flight-checks:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.cost_check.outputs.should_run }}
      estimated_cost: ${{ steps.cost_check.outputs.estimated_cost }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Deno
      uses: denoland/setup-deno@v1
      with:
        deno-version: '2.x'

    - name: Check cost limits
      id: cost_check
      run: |
        echo "Checking daily cost limits..."

        # Read cost control configuration
        if [ -f "deploy-control.json" ]; then
          DAILY_LIMIT=$(cat deploy-control.json | grep -o '"cost_limit_daily":[^,}]*' | cut -d':' -f2 | tr -d ' ",' || echo "50")
        else
          DAILY_LIMIT=50
        fi

        echo "Daily cost limit: $DAILY_LIMIT"

        # Estimate current usage (this would typically call your cost tracking API)
        ESTIMATED_COST=25  # Placeholder - replace with actual cost check

        echo "estimated_cost=$ESTIMATED_COST" >> $GITHUB_OUTPUT

        if [ "${{ inputs.force_run }}" == "true" ]; then
          echo "Force run enabled, bypassing cost checks"
          echo "should_run=true" >> $GITHUB_OUTPUT
        elif [ "$ESTIMATED_COST" -lt "$DAILY_LIMIT" ]; then
          echo "Cost check passed: $ESTIMATED_COST < $DAILY_LIMIT"
          echo "should_run=true" >> $GITHUB_OUTPUT
        else
          echo "Cost limit exceeded: $ESTIMATED_COST >= $DAILY_LIMIT"
          echo "should_run=false" >> $GITHUB_OUTPUT
        fi

    - name: Check system health
      run: |
        echo "Checking system health..."

        # Check Supabase connectivity
        if curl -f -s "$SUPABASE_URL/rest/v1/" -H "apikey: $SUPABASE_ANON_KEY" > /dev/null; then
          echo "‚úÖ Supabase connection healthy"
        else
          echo "‚ùå Supabase connection failed"
          exit 1
        fi

        echo "‚úÖ System health checks passed"

  populate-queue:
    name: Populate Scraping Queue
    runs-on: ubuntu-latest
    needs: pre-flight-checks
    if: needs.pre-flight-checks.outputs.should_run == 'true'

    strategy:
      matrix:
        region: ${{ fromJson(inputs.region == 'all' && '["atlanta", "austin", "dallas", "houston"]' || format('["{0}"]', inputs.region)) }}
      fail-fast: false
      max-parallel: 2

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Deno
      uses: denoland/setup-deno@v1
      with:
        deno-version: '2.x'

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/deno
        key: ${{ runner.os }}-deno-${{ hashFiles('**/import_map.json', '**/deno.json') }}
        restore-keys: |
          ${{ runner.os }}-deno-

    - name: Populate queue for ${{ matrix.region }}
      run: |
        echo "üöÄ Populating scraping queue for region: ${{ matrix.region }}"

        if [ "${{ inputs.dry_run }}" == "true" ]; then
          echo "üß™ Running in dry-run mode"
          export DRY_RUN=true
        fi

        # Set region-specific configuration
        export TARGET_REGION="${{ matrix.region }}"
        export ENABLE_AI_PRICING=true
        export ENABLE_FRONTEND_SYNC=true
        export ENABLE_MARKET_INTELLIGENCE=true
        export BATCH_SIZE=50

        # Call command-station Edge Function to populate queue
        # This will add scraping jobs to the queue for the specified region
        RESPONSE=$(curl -s -X POST "${{ secrets.SUPABASE_URL }}/functions/v1/command-station" \
          -H "Authorization: Bearer ${{ secrets.SUPABASE_ANON_KEY }}" \
          -H "Content-Type: application/json" \
          -d "{
            \"action\": \"populate_queue\",
            \"region\": \"${{ matrix.region }}\",
            \"batch_size\": 50,
            \"dry_run\": ${{ inputs.dry_run == 'true' && 'true' || 'false' }}
          }")

        # Check if the request was successful
        if echo "$RESPONSE" | grep -q '"status":"success"'; then
          echo "‚úÖ Queue populated successfully for ${{ matrix.region }}"
          echo "Response: $RESPONSE"
        else
          echo "‚ùå Failed to populate queue for ${{ matrix.region }}"
          echo "Response: $RESPONSE"
          exit 1
        fi

    - name: Generate region report
      if: always()
      run: |
        echo "üìä Generating report for ${{ matrix.region }}..."

        # Create a simple report
        cat > region_report_${{ matrix.region }}.json << EOF
        {
          "region": "${{ matrix.region }}",
          "timestamp": "$(date -u -Iseconds)",
          "status": "${{ job.status }}",
          "dry_run": "${{ inputs.dry_run }}",
          "estimated_cost": "${{ needs.pre-flight-checks.outputs.estimated_cost }}",
          "queue_populated": ${{ job.status == 'success' && 'true' || 'false' }}
        }
        EOF

    - name: Upload region report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-reports
        path: region_report_*.json
        retention-days: 30

  trigger-processing:
    name: Trigger Queue Processing
    runs-on: ubuntu-latest
    needs: [pre-flight-checks, populate-queue]
    if: needs.pre-flight-checks.outputs.should_run == 'true' && inputs.dry_run != 'true'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Trigger batch processing
      run: |
        echo "üîÑ Triggering batch processing for queued jobs..."

        # Call command-station to start processing the queue
        RESPONSE=$(curl -s -X POST "${{ secrets.SUPABASE_URL }}/functions/v1/command-station" \
          -H "Authorization: Bearer ${{ secrets.SUPABASE_ANON_KEY }}" \
          -H "Content-Type: application/json" \
          -d "{
            \"action\": \"start_batch\",
            \"batch_size\": 50,
            \"regions\": ${{ inputs.region == 'all' && '[\"atlanta\", \"austin\", \"dallas\", \"houston\"]' || format('[\"{0}\"]', inputs.region) }}
          }")

        # Check if batch processing started
        if echo "$RESPONSE" | grep -q '"status":"batch_started"'; then
          echo "‚úÖ Batch processing started successfully"
          echo "Response: $RESPONSE"
        else
          echo "‚ùå Failed to start batch processing"
          echo "Response: $RESPONSE"
          exit 1
        fi

  post-processing:
    name: Post-Processing & Reporting
    runs-on: ubuntu-latest
    needs: [pre-flight-checks, populate-queue, trigger-processing]
    if: always()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download reports
      uses: actions/download-artifact@v4
      with:
        name: scraper-reports
        path: ./reports/
      continue-on-error: true

    - name: Generate summary report
      run: |
        echo "üìã Generating summary report..."

        # Count successful and failed regions
        SUCCESS_COUNT=0
        FAILED_COUNT=0
        TOTAL_PROPERTIES=0

        # Check if reports directory exists
        if [ -d "./reports" ] && [ "$(ls -A ./reports 2>/dev/null)" ]; then
          echo "Found reports directory with files"
          for report in ./reports/region_report_*.json; do
            if [ -f "$report" ]; then
              echo "Processing report: $report"
              REGION=$(cat "$report" | grep -o '"region":"[^"]*' | cut -d'"' -f4 2>/dev/null || echo "unknown")
              STATUS=$(cat "$report" | grep -o '"status":"[^"]*' | cut -d'"' -f4 2>/dev/null || echo "unknown")

              if [ "$STATUS" == "success" ]; then
                SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
              else
                FAILED_COUNT=$((FAILED_COUNT + 1))
              fi
            fi
          done
        else
          echo "‚ö†Ô∏è No reports found - queue population may have failed early"
          # Check job outcomes from the workflow context
          FAILED_COUNT=1
        fi

        echo "SUCCESS_COUNT=$SUCCESS_COUNT" >> $GITHUB_ENV
        echo "FAILED_COUNT=$FAILED_COUNT" >> $GITHUB_ENV
        echo "TOTAL_REGIONS=$((SUCCESS_COUNT + FAILED_COUNT))" >> $GITHUB_ENV

    - name: Send Slack notification
      if: always() && secrets.SLACK_WEBHOOK_URL
      run: |
        if [ "${{ needs.pre-flight-checks.outputs.should_run }}" == "false" ]; then
          MESSAGE="‚è∏Ô∏è Weekly scraper skipped due to cost limits\nEstimated cost: \$\${{ needs.pre-flight-checks.outputs.estimated_cost }}"
        elif [ "${{ inputs.dry_run }}" == "true" ]; then
          MESSAGE="üß™ Weekly scraper dry run completed\nRegions processed: $TOTAL_REGIONS\nSuccessful: $SUCCESS_COUNT\nFailed: $FAILED_COUNT"
        elif [ "$TOTAL_REGIONS" -eq "0" ]; then
          MESSAGE="‚ö†Ô∏è Weekly scraper encountered issues\nNo region reports generated\nCheck workflow logs for details"
        else
          MESSAGE="üè† Weekly scraper queue populated!\nRegions processed: $TOTAL_REGIONS\nSuccessful: $SUCCESS_COUNT\nFailed: $FAILED_COUNT\nEstimated cost: \$\${{ needs.pre-flight-checks.outputs.estimated_cost }}"
        fi

        if [ -n "${{ secrets.SLACK_WEBHOOK_URL }}" ]; then
          curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"$MESSAGE\"}" \
            ${{ secrets.SLACK_WEBHOOK_URL }}
        else
          echo "Slack notification: $MESSAGE"
        fi

    - name: Update deployment status
      run: |
        echo "üìà Weekly scraper summary:"
        echo "- Total regions: $TOTAL_REGIONS"
        echo "- Successful: $SUCCESS_COUNT"
        echo "- Failed: $FAILED_COUNT"
        echo "- Estimated cost: ${{ needs.pre-flight-checks.outputs.estimated_cost }}"
        echo "- Dry run: ${{ inputs.dry_run }}"

        if [ "$FAILED_COUNT" -gt 0 ]; then
          echo "‚ö†Ô∏è  Some regions failed - check logs for details"
        else
          echo "‚úÖ All regions completed successfully!"
        fi